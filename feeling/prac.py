import pandas as pd
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder


df=pd.read_csv('data/train_v1.csv')

df.value_counts()
df.info()

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False





import pandas as pd
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder


df_encoded = df.copy()
for col in df_encoded.select_dtypes(include='object').columns:
    if col not in ['id', 'registration_time']:
        df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col].astype(str))

X = df_encoded.drop(columns=['passorfail', 'registration_time'])
y = df_encoded['passorfail']

# ğŸ”¹ XGBoost DMatrix ì‚¬ìš©
model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
model.fit(X, y)

# âœ… SHAP TreeExplainer ì‚¬ìš© (xgboost ì „ìš©)
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# ğŸ”¹ SHAP DataFrame ìƒì„±
shap_df = pd.DataFrame(shap_values, columns=X.columns)
shap_df['mold_code'] = df['mold_code'].values

# ğŸ”¹ ë³´ê³  ì‹¶ì€ ë³€ìˆ˜ 5ê°œ
selected_features = ['biscuit_thickness', 'lower_mold_temp2', 'upper_mold_temp1',
                     'upper_mold_temp2', 'cast_pressure']

mold_code_top5_positive = []

for mold, group in shap_df.groupby('mold_code'):
    # ì–‘ìˆ˜ ê¸°ì—¬ë„ë§Œ í‰ê· 
    mean_shap = group[selected_features].apply(lambda x: x[x > 0].mean())
    
    # ë†’ì€ ìˆœ ì •ë ¬ í›„ top 5
    top5 = mean_shap.sort_values(ascending=False).dropna()[:5]
    
    # ê²°ê³¼ ì €ì¥
    row = {'mold_code': mold}
    for var, val in top5.items():
        row[var] = round(val, 5)
    
    mold_code_top5_positive.append(row)

# ìµœì¢… DataFrame
top5_positive_df = pd.DataFrame(mold_code_top5_positive)

# í™•ì¸
print(top5_positive_df.head())




# ----------------test, train ë°ì´í„° ìœ ì‚¬ì„± í™•ì¸--------------
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from xgboost import XGBClassifier
from sklearn.metrics import f1_score, classification_report

# ë°ì´í„° ë¡œë“œ
train_v1 = pd.read_csv('data/train_v1.csv')

# ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°
drop_cols = ['id', 'registration_time']
train_v1 = train_v1.drop(columns=drop_cols)

# ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
for col in ['working', 'tryshot_signal', 'heating_furnace', 'mold_code']:
    le = LabelEncoder()
    train_v1[col] = le.fit_transform(train_v1[col])

# íƒ€ê²Ÿ/í”¼ì²˜ ë¶„ë¦¬
X = train_v1.drop(columns=['passorfail'])
y = train_v1['passorfail']

# ë°ì´í„° ë¶„í•  (Stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# XGBoost ëª¨ë¸ ì •ì˜ (ë¶ˆê· í˜• ëŒ€ì‘)
xgb_model = XGBClassifier(
    random_state=42,
    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),
    eval_metric='logloss',
    use_label_encoder=False,
)

# ëª¨ë¸ í•™ìŠµ
xgb_model.fit(X_train, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred = xgb_model.predict(X_test)
f1 = f1_score(y_test, y_pred)
print(f"F1-score: {f1:.4f}")
print(classification_report(y_test, y_pred))

from sklearn.inspection import permutation_importance

# permutation importance ê³„ì‚°
result = permutation_importance(
    xgb_model, X_test, y_test,
    n_repeats=10,   # ë°˜ë³µ íšŸìˆ˜(ë†’ì„ìˆ˜ë¡ ì•ˆì •ì )
    random_state=42,
    n_jobs=-1       # ëª¨ë“  ì½”ì–´ ì‚¬ìš©
)


# ê²°ê³¼ ì •ë¦¬ (ì¤‘ìš”ë„ ë‚´ë¦¼ì°¨ìˆœ)
importances = pd.DataFrame({
    'feature': X_test.columns,
    'importance_mean': result.importances_mean,
    'importance_std': result.importances_std
}).sort_values(by='importance_mean', ascending=False)

print(importances)

# ----------------------------------------
import matplotlib.pyplot as plt

# ìƒìœ„ 10ê°œ ë³€ìˆ˜ë§Œ ì¶”ì¶œ
topn = 10
top_features = importances.head(topn)

plt.figure(figsize=(8, 5))
plt.barh(top_features['feature'][::-1], top_features['importance_mean'][::-1], 
         xerr=top_features['importance_std'][::-1])
plt.xlabel("Permutation Importance (Mean)")
plt.title(f"Top {topn} Feature Importances (Permutation)")
plt.tight_layout()
plt.show()

# -------------------------------
import shap

# 1ï¸ TreeExplainer ê°ì²´ ìƒì„±
explainer = shap.TreeExplainer(xgb_model)

# 2ï¸ SHAP ê°’ ê³„ì‚° (X_test ëŒ€ìƒ)
shap_values = explainer.shap_values(X_test)

# 3ï¸ summary_plot (ì „ì²´ ë³€ìˆ˜ë³„ ì˜í–¥ë„)
shap.summary_plot(shap_values, X_test, plot_type="bar")     # ë§‰ëŒ€ê·¸ë˜í”„(í‰ê·  ì ˆëŒ€ê°’)
shap.summary_plot(shap_values, X_test)                      # ì  êµ¬ë¦„ plot(ë¶„í¬ì™€ ì˜í–¥ ë™ì‹œ)



from xgboost import to_graphviz
dot = to_graphviz(xgb_model, num_trees=0, rankdir='LR', with_stats=True)
dot.render('xgb_tree0_with_stats.dot')




















import pandas as pd


xgb_model.get_booster().dump_model('tree_dump.txt', with_stats=True)

def get_leaf_conditions(tree_txt_path):
    with open(tree_txt_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    path_stack = []
    leaf_info = {}
    for line in lines:
        indent = len(line) - len(line.lstrip())
        content = line.strip()
        if ':' in content and 'leaf=' not in content:
            # ë¶„ê¸° ë…¸ë“œ
            cond = content.split('[')[1].split(']')[0]
            path_stack = path_stack[:indent//2] + [cond]
        elif 'leaf=' in content:
            leaf_idx = int(content.split(':')[0])
            cond_path = ' & '.join(path_stack)
            leaf_info[leaf_idx] = cond_path
    return leaf_info

leaf_condition_map = get_leaf_conditions('tree_dump.txt')


# íŠ¸ë¦¬ 0ë²ˆ ë¦¬í”„ index ì¶”ì¶œ
leaf_nodes = xgb_model.apply(X_test)[:, 0]
result_df = pd.DataFrame({'leaf': leaf_nodes, 'label': y_test.values})

# ë¦¬í”„ë³„ ì–‘í’ˆ/ë¶ˆëŸ‰ count
leaf_stats = result_df.groupby('leaf')['label'].value_counts().unstack(fill_value=0)
leaf_stats.columns = ['ì–‘í’ˆ(0)', 'ë¶ˆëŸ‰(1)']

# ì „ì²´ ìƒ˜í”Œìˆ˜ ë° ë¶ˆëŸ‰ë¹„ìœ¨ ì¶”ê°€
leaf_stats['ì „ì²´ ìƒ˜í”Œìˆ˜'] = leaf_stats['ì–‘í’ˆ(0)'] + leaf_stats['ë¶ˆëŸ‰(1)']
leaf_stats['ë¶ˆëŸ‰ë¹„ìœ¨'] = leaf_stats['ë¶ˆëŸ‰(1)'] / leaf_stats['ì „ì²´ ìƒ˜í”Œìˆ˜']

# ì¡°ê±´ ê²½ë¡œ ì—°ê²°
leaf_stats['ì¡°ê±´ê²½ë¡œ'] = leaf_stats.index.map(lambda idx: leaf_condition_map.get(idx, ''))

# ê²°ê³¼ í™•ì¸ (ìƒìœ„ 10ê°œ)
print(leaf_stats[['ì–‘í’ˆ(0)', 'ë¶ˆëŸ‰(1)', 'ì „ì²´ ìƒ˜í”Œìˆ˜', 'ë¶ˆëŸ‰ë¹„ìœ¨', 'ì¡°ê±´ê²½ë¡œ']].head(10))